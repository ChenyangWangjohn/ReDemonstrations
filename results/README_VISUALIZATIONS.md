# HellaSwag ICL Experiment Results Visualization

## ğŸ“Š Generated Files

### Tables
1. **`results_summary.md`** - Markdown table with all experiment results
2. **`results_summary.csv`** - CSV format for easy data analysis

### Visualizations

#### 1. **`accuracy_comparison.png`** - Overall Accuracy Comparison
- Bar chart comparing all experiments
- Color-coded by model type (M_base = blue, M_finetuned = red)
- Shows accuracy percentage for each experiment
- **Key Insight**: Visual comparison of all experimental conditions

#### 2. **`grouped_comparison.png`** - Base vs Finetuned Models
- Grouped bar chart comparing M_base and M_finetuned across settings
- Groups experiments by setting type (Zero-Shot, Random ctx_a, Gold ctx_a)
- **Key Insight**: Direct comparison of model performance across different contexts

#### 3. **`hypothesis_validation.png`** - Hypothesis Testing
- Two-panel visualization:
  - **Left Panel (H1)**: Common Sense Hypothesis
    - Tests: Gold ctx_a > Zero-Shot > Random ctx_a
    - Shows accuracy for Zero-Shot, Random ctx_a, and Gold ctx_a
  - **Right Panel (H3)**: Corrupted Model Hypothesis
    - Tests: M_finetuned Zero-Shot < M_base Zero-Shot
    - Shows degradation arrow if hypothesis is supported
- **Key Insight**: Visual validation of research hypotheses

#### 4. **`confidence_distribution.png`** - Model Confidence Analysis
- Histogram showing distribution of maximum probabilities across experiments
- 2x3 grid layout (one subplot per experiment)
- Shows mean confidence level for each experiment
- **Key Insight**: Understanding model confidence and uncertainty patterns

#### 5. **`improvement_analysis.png`** - Few-Shot vs Zero-Shot Improvement
- Bar chart showing accuracy improvement from Few-Shot demonstrations
- Compares Gold ctx_a vs Zero-Shot and Random ctx_a vs Zero-Shot
- Separate analysis for M_base and M_finetuned models
- **Key Insight**: Quantifying the benefit of in-context learning

## ğŸ“ˆ Current Results Summary

| Experiment | Model | Setting | ctx_a Type | Accuracy | Accuracy (%) |
|------------|-------|---------|------------|----------|--------------|
| Experiment A | M_base | Zero-Shot | None | 0.3430 | 34.30% |
| Experiment B | M_base | Few-Shot | Gold | 0.3905 | 39.05% |
| Experiment C | M_base | Few-Shot | Random | 0.3735 | 37.35% |

## ğŸ” Key Findings

1. **Few-Shot Learning Works**: Both Few-Shot experiments outperform Zero-Shot
   - Gold ctx_a: +4.75% improvement
   - Random ctx_a: +3.05% improvement

2. **Semantic Content Matters**: Gold ctx_a performs better than Random ctx_a
   - Gold ctx_a: 39.05%
   - Random ctx_a: 37.35%
   - Difference: +1.70%

3. **Performance Ranking**: Gold ctx_a > Random ctx_a > Zero-Shot
   - Supports H1 (Common Sense Hypothesis)

## ğŸ“ Usage

To regenerate visualizations after running new experiments:

```bash
cd /data/johnwang/ICL/ReDemonstrations
conda activate icl-qwen
python scripts/visualize_results.py \
    --results_dir /data/johnwang/ICL/result \
    --output_dir /data/johnwang/ICL/result
```

## ğŸ¨ Visualization Features

- **High Resolution**: All charts saved at 300 DPI for publication quality
- **Color Coding**: Consistent color scheme across all visualizations
- **Professional Styling**: Clean, modern design suitable for presentations
- **Value Labels**: All bars include exact percentage values
- **Grid Lines**: Subtle grid lines for easy reading

## ğŸ“Œ Notes

- Experiments D, E, F (M_finetuned) will be added when finetuned model results are available
- All visualizations automatically adapt to available data
- Charts are optimized for both screen viewing and printing

